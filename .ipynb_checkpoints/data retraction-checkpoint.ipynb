{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a832f76c-5d5e-487d-9d94-2cce92875732",
   "metadata": {},
   "source": [
    "# Data Retraction from X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea15900e-5057-4308-8849-990371847c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tweepy\n",
      "  Downloading tweepy-4.15.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting oauthlib<4,>=3.2.0 (from tweepy)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in d:\\anaconda\\lib\\site-packages (from tweepy) (2.32.3)\n",
      "Collecting requests-oauthlib<3,>=1.2.0 (from tweepy)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2024.12.14)\n",
      "Downloading tweepy-4.15.0-py3-none-any.whl (99 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, tweepy\n",
      "Successfully installed oauthlib-3.2.2 requests-oauthlib-2.0.0 tweepy-4.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "436d4078-e6ab-4667-adab-ac62816854f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Twitter API credentials (replace with your own)\n",
    "BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAAFnGzAEAAAAAw3J6M6RsI%2FG%2FR%2FnyoKemG9ezJlI%3D3VBkk61leyvfliYTLgD4HNghRLYtmMrNfn1upFcmykDisSxVlg\"\n",
    "\n",
    "# Authenticate with Twitter API\n",
    "client = tweepy.Client(bearer_token=BEARER_TOKEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2f382d0-533d-49e8-a243-6aaaa558d576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def wait_for_rate_limit():\n",
    "    \"\"\"Checks and waits for rate limit reset if necessary.\"\"\"\n",
    "    response = client.get_rate_limit_status()\n",
    "    remaining_requests = response[\"resources\"][\"search\"][\"/search/tweets\"][\"remaining\"]\n",
    "    reset_time = response[\"resources\"][\"search\"][\"/search/tweets\"][\"reset\"]\n",
    "    \n",
    "    if remaining_requests == 0:\n",
    "        wait_time = max(reset_time - time.time(), 60)  # Ensure at least 60 seconds wait\n",
    "        print(f\"Rate limit reached. Waiting for {wait_time} seconds...\")\n",
    "        time.sleep(wait_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ca50682-ab4a-4d2b-875c-c9bdee339b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_tweets(keyword, start_date, end_date, max_results=100):\n",
    "    \"\"\"Fetch tweets containing a specific keyword within a date range with rate limit handling.\"\"\"\n",
    "    query = f\"{keyword} -is:retweet lang:en\"  # Filtering out retweets & non-English tweets\n",
    "    tweets = []\n",
    "    print(f\"Starting tweet fetching for keyword: {keyword}\")\n",
    "    \n",
    "    try:\n",
    "        for tweet in tweepy.Paginator(client.search_recent_tweets, \n",
    "                                      query=query, \n",
    "                                      start_time=start_date, \n",
    "                                      end_time=end_date, \n",
    "                                      max_results=50,  # Reduce batch size to avoid hitting rate limits\n",
    "                                      tweet_fields=[\"created_at\", \"text\", \"author_id\"]):\n",
    "            wait_for_rate_limit()  # Check rate limits before each request\n",
    "            tweets.extend(tweet.data or [])\n",
    "            print(f\"Fetched {len(tweets)} tweets so far...\")\n",
    "            if len(tweets) >= max_results:\n",
    "                break\n",
    "            \n",
    "            time.sleep(5)  # Small delay to avoid aggressive querying\n",
    "    \n",
    "    except tweepy.TooManyRequests as e:\n",
    "        print(\"Rate limit reached. Waiting before retrying...\")\n",
    "        reset_time = int(e.response.headers.get(\"x-rate-limit-reset\", time.time() + 60))  # Get reset time from headers\n",
    "        wait_time = max(reset_time - time.time(), 60)  # Ensure at least 60 seconds wait\n",
    "        time.sleep(wait_time)\n",
    "        return fetch_tweets(keyword, start_date, end_date, max_results)  # Retry after waiting\n",
    "    \n",
    "    print(\"Tweet fetching completed.\")\n",
    "    return tweets[:max_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2df953c-60a5-4e87-9ac6-9e23a77b9c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DIamond\\AppData\\Local\\Temp\\ipykernel_23700\\3997376793.py:3: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  tomorrow = (datetime.datetime.utcnow() + datetime.timedelta(days=1)).strftime(\"%Y-%m-%dT00:00:00Z\")\n",
      "C:\\Users\\DIamond\\AppData\\Local\\Temp\\ipykernel_23700\\3997376793.py:4: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  tomorrow_after = (datetime.datetime.utcnow() + datetime.timedelta(days=2)).strftime(\"%Y-%m-%dT00:00:00Z\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the script...\n",
      "Starting tweet fetching for keyword: medical school\n",
      "Rate limit reached. Waiting before retrying...\n",
      "Starting tweet fetching for keyword: medical school\n"
     ]
    },
    {
     "ename": "BadRequest",
     "evalue": "400 Bad Request\nInvalid 'start_time':'2025-02-15T00:00Z'. 'start_time' must be a minimum of 10 seconds prior to the request time.\nInvalid 'end_time':'2025-02-14T00:00Z'. 'end_time' must be a minimum of 10 seconds prior to the request time.\nInvalid 'start_time':'2025-02-15T00:00Z'. 'start_time' must be before 'end_time':2025-02-14T00:00Z",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTooManyRequests\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 8\u001b[0m, in \u001b[0;36mfetch_tweets\u001b[1;34m(keyword, start_date, end_date, max_results)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tweet \u001b[38;5;129;01min\u001b[39;00m tweepy\u001b[38;5;241m.\u001b[39mPaginator(client\u001b[38;5;241m.\u001b[39msearch_recent_tweets, \n\u001b[0;32m      9\u001b[0m                                   query\u001b[38;5;241m=\u001b[39mquery, \n\u001b[0;32m     10\u001b[0m                                   start_time\u001b[38;5;241m=\u001b[39mstart_date, \n\u001b[0;32m     11\u001b[0m                                   end_time\u001b[38;5;241m=\u001b[39mend_date, \n\u001b[0;32m     12\u001b[0m                                   max_results\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,  \u001b[38;5;66;03m# Reduce batch size to avoid hitting rate limits\u001b[39;00m\n\u001b[0;32m     13\u001b[0m                                   tweet_fields\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreated_at\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthor_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m     14\u001b[0m         wait_for_rate_limit()  \u001b[38;5;66;03m# Check rate limits before each request\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\tweepy\\pagination.py:126\u001b[0m, in \u001b[0;36mPaginationIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpagination_token\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pagination_token\n\u001b[1;32m--> 126\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, Response):\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\tweepy\\client.py:1270\u001b[0m, in \u001b[0;36mClient.search_recent_tweets\u001b[1;34m(self, query, user_auth, **params)\u001b[0m\n\u001b[0;32m   1269\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m query\n\u001b[1;32m-> 1270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m   1271\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/2/tweets/search/recent\u001b[39m\u001b[38;5;124m\"\u001b[39m, params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m   1272\u001b[0m     endpoint_parameters\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1273\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_time\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpansions\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_results\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedia.fields\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1274\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext_token\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplace.fields\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoll.fields\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1275\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msince_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msort_order\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_time\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtweet.fields\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1276\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muntil_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser.fields\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1277\u001b[0m     ), data_type\u001b[38;5;241m=\u001b[39mTweet, user_auth\u001b[38;5;241m=\u001b[39muser_auth\n\u001b[0;32m   1278\u001b[0m )\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\tweepy\\client.py:129\u001b[0m, in \u001b[0;36mBaseClient._make_request\u001b[1;34m(self, method, route, params, endpoint_parameters, json, data_type, user_auth)\u001b[0m\n\u001b[0;32m    127\u001b[0m request_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_params(params, endpoint_parameters)\n\u001b[1;32m--> 129\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(method, route, params\u001b[38;5;241m=\u001b[39mrequest_params,\n\u001b[0;32m    130\u001b[0m                         json\u001b[38;5;241m=\u001b[39mjson, user_auth\u001b[38;5;241m=\u001b[39muser_auth)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_type \u001b[38;5;129;01mis\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mResponse:\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\tweepy\\client.py:115\u001b[0m, in \u001b[0;36mBaseClient.request\u001b[1;34m(self, method, route, params, json, user_auth)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TooManyRequests(response)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m:\n",
      "\u001b[1;31mTooManyRequests\u001b[0m: 429 Too Many Requests\nToo Many Requests",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mBadRequest\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m max_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting the script...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m tweets \u001b[38;5;241m=\u001b[39m fetch_tweets(keyword, start_date, end_date, max_results)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Convert to DataFrame\u001b[39;00m\n\u001b[0;32m     13\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([{ \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreated_at\u001b[39m\u001b[38;5;124m\"\u001b[39m: t\u001b[38;5;241m.\u001b[39mcreated_at, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: t\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthor_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: t\u001b[38;5;241m.\u001b[39mauthor_id } \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tweets])\n",
      "Cell \u001b[1;32mIn[6], line 27\u001b[0m, in \u001b[0;36mfetch_tweets\u001b[1;34m(keyword, start_date, end_date, max_results)\u001b[0m\n\u001b[0;32m     25\u001b[0m     wait_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(reset_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mtime(), \u001b[38;5;241m60\u001b[39m)  \u001b[38;5;66;03m# Ensure at least 60 seconds wait\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(wait_time)\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fetch_tweets(keyword, start_date, end_date, max_results)  \u001b[38;5;66;03m# Retry after waiting\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTweet fetching completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tweets[:max_results]\n",
      "Cell \u001b[1;32mIn[6], line 8\u001b[0m, in \u001b[0;36mfetch_tweets\u001b[1;34m(keyword, start_date, end_date, max_results)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting tweet fetching for keyword: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkeyword\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tweet \u001b[38;5;129;01min\u001b[39;00m tweepy\u001b[38;5;241m.\u001b[39mPaginator(client\u001b[38;5;241m.\u001b[39msearch_recent_tweets, \n\u001b[0;32m      9\u001b[0m                                   query\u001b[38;5;241m=\u001b[39mquery, \n\u001b[0;32m     10\u001b[0m                                   start_time\u001b[38;5;241m=\u001b[39mstart_date, \n\u001b[0;32m     11\u001b[0m                                   end_time\u001b[38;5;241m=\u001b[39mend_date, \n\u001b[0;32m     12\u001b[0m                                   max_results\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,  \u001b[38;5;66;03m# Reduce batch size to avoid hitting rate limits\u001b[39;00m\n\u001b[0;32m     13\u001b[0m                                   tweet_fields\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreated_at\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthor_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m     14\u001b[0m         wait_for_rate_limit()  \u001b[38;5;66;03m# Check rate limits before each request\u001b[39;00m\n\u001b[0;32m     15\u001b[0m         tweets\u001b[38;5;241m.\u001b[39mextend(tweet\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;129;01mor\u001b[39;00m [])\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\tweepy\\pagination.py:126\u001b[0m, in \u001b[0;36mPaginationIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpagination_token\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pagination_token\n\u001b[1;32m--> 126\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, Response):\n\u001b[0;32m    129\u001b[0m     meta \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mmeta\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\tweepy\\client.py:1270\u001b[0m, in \u001b[0;36mClient.search_recent_tweets\u001b[1;34m(self, query, user_auth, **params)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"search_recent_tweets( \\\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m \u001b[38;5;124;03m    query, *, end_time=None, expansions=None, max_results=None, \\\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;124;03m    media_fields=None, next_token=None, place_fields=None, \\\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1267\u001b[0m \u001b[38;5;124;03m.. _Academic Research Project: https://developer.twitter.com/en/docs/projects\u001b[39;00m\n\u001b[0;32m   1268\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1269\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m query\n\u001b[1;32m-> 1270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m   1271\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/2/tweets/search/recent\u001b[39m\u001b[38;5;124m\"\u001b[39m, params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m   1272\u001b[0m     endpoint_parameters\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1273\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_time\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpansions\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_results\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedia.fields\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1274\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext_token\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplace.fields\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoll.fields\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1275\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msince_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msort_order\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_time\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtweet.fields\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1276\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muntil_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser.fields\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1277\u001b[0m     ), data_type\u001b[38;5;241m=\u001b[39mTweet, user_auth\u001b[38;5;241m=\u001b[39muser_auth\n\u001b[0;32m   1278\u001b[0m )\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\tweepy\\client.py:129\u001b[0m, in \u001b[0;36mBaseClient._make_request\u001b[1;34m(self, method, route, params, endpoint_parameters, json, data_type, user_auth)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_request\u001b[39m(\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m, method, route, params\u001b[38;5;241m=\u001b[39m{}, endpoint_parameters\u001b[38;5;241m=\u001b[39m(), json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    125\u001b[0m     data_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, user_auth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    126\u001b[0m ):\n\u001b[0;32m    127\u001b[0m     request_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_params(params, endpoint_parameters)\n\u001b[1;32m--> 129\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(method, route, params\u001b[38;5;241m=\u001b[39mrequest_params,\n\u001b[0;32m    130\u001b[0m                             json\u001b[38;5;241m=\u001b[39mjson, user_auth\u001b[38;5;241m=\u001b[39muser_auth)\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_type \u001b[38;5;129;01mis\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mResponse:\n\u001b[0;32m    133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\tweepy\\client.py:96\u001b[0m, in \u001b[0;36mBaseClient.request\u001b[1;34m(self, method, route, params, json, user_auth)\u001b[0m\n\u001b[0;32m     88\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived API response: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHeaders: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     93\u001b[0m )\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadRequest(response)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Unauthorized(response)\n",
      "\u001b[1;31mBadRequest\u001b[0m: 400 Bad Request\nInvalid 'start_time':'2025-02-15T00:00Z'. 'start_time' must be a minimum of 10 seconds prior to the request time.\nInvalid 'end_time':'2025-02-14T00:00Z'. 'end_time' must be a minimum of 10 seconds prior to the request time.\nInvalid 'start_time':'2025-02-15T00:00Z'. 'start_time' must be before 'end_time':2025-02-14T00:00Z"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    keyword = \"medical school\" or \"rama\"\n",
    "    tomorrow = (datetime.datetime.utcnow() + datetime.timedelta(days=1)).strftime(\"%Y-%m-%dT00:00:00Z\")\n",
    "    tomorrow_after = (datetime.datetime.utcnow() + datetime.timedelta(days=2)).strftime(\"%Y-%m-%dT00:00:00Z\")\n",
    "    start_date = tomorrow_after  # Start date from tomorrow\n",
    "    end_date = tomorrow  # End date today\n",
    "    max_results = 200\n",
    "    \n",
    "    print(\"Starting the script...\")\n",
    "    tweets = fetch_tweets(keyword, start_date, end_date, max_results)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame([{ \"created_at\": t.created_at, \"text\": t.text, \"author_id\": t.author_id } for t in tweets])\n",
    "    print(\"Fetched tweets preview:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(\"filtered_tweets.csv\", index=False)\n",
    "    print(\"Tweets saved to filtered_tweets.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
