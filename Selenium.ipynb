{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae158fc5-de90-4754-ad95-df5c6a668b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in d:\\anaconda\\envs\\bridge\\lib\\site-packages (4.29.0)\n",
      "Requirement already satisfied: webdriver-manager in d:\\anaconda\\envs\\bridge\\lib\\site-packages (4.0.2)\n",
      "Collecting googlesearch-python\n",
      "  Downloading googlesearch_python-1.3.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in d:\\anaconda\\envs\\bridge\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
      "Requirement already satisfied: trio~=0.17 in d:\\anaconda\\envs\\bridge\\lib\\site-packages (from selenium) (0.29.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in d:\\anaconda\\envs\\bridge\\lib\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in d:\\anaconda\\envs\\bridge\\lib\\site-packages (from selenium) (2025.1.31)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in d:\\anaconda\\envs\\bridge\\lib\\site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in d:\\anaconda\\envs\\bridge\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\envs\\bridge\\lib\\site-packages (from webdriver-manager) (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in d:\\anaconda\\envs\\bridge\\lib\\site-packages (from webdriver-manager) (1.0.1)\n",
      "Requirement already satisfied: packaging in d:\\anaconda\\envs\\bridge\\lib\\site-packages (from webdriver-manager) (24.2)\n",
      "Requirement already satisfied: beautifulsoup4>=4.9 in d:\\anaconda\\envs\\bridge\\lib\\site-packages (from googlesearch-python) (4.13.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda\\envs\\bridge\\lib\\site-packages (from beautifulsoup4>=4.9->googlesearch-python) (2.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\envs\\bridge\\lib\\site-packages (from requests->webdriver-manager) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\envs\\bridge\\lib\\site-packages (from requests->webdriver-manager) (3.10)\n",
      "Requirement already satisfied: attrs>=23.2.0 in d:\\anaconda\\envs\\bridge\\lib\\site-packages (from trio~=0.17->selenium) (25.1.0)\n",
      "Requirement already satisfied: sortedcontainers in d:\\anaconda\\envs\\bridge\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in d:\\anaconda\\envs\\bridge\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in d:\\anaconda\\envs\\bridge\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in d:\\anaconda\\envs\\bridge\\lib\\site-packages (from trio~=0.17->selenium) (1.17.1)\n",
      "Requirement already satisfied: exceptiongroup in d:\\anaconda\\envs\\bridge\\lib\\site-packages (from trio~=0.17->selenium) (1.2.2)\n",
      "Requirement already satisfied: wsproto>=0.14 in d:\\anaconda\\envs\\bridge\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in d:\\anaconda\\envs\\bridge\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in d:\\anaconda\\envs\\bridge\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.22)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in d:\\anaconda\\envs\\bridge\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Downloading googlesearch_python-1.3.0-py3-none-any.whl (5.6 kB)\n",
      "Installing collected packages: googlesearch-python\n",
      "Successfully installed googlesearch-python-1.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium webdriver-manager googlesearch-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20784ed9-5415-473b-91b0-a1939d138854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening https://www.instagram.com/explore/tags/รามาธิบดี/\n",
      "Found 0 posts.\n",
      "No captions found.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "# Set up Selenium WebDriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Run in headless mode\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")  # Reduce bot detection\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--window-size=1920,1080\")\n",
    "\n",
    "# Initialize WebDriver\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Define the hashtag to search for\n",
    "HASHTAG = \"รามาธิบดี\"  # Change to your target hashtag\n",
    "URL = f\"https://www.instagram.com/explore/tags/{HASHTAG}/\"\n",
    "\n",
    "# Open Instagram hashtag page\n",
    "print(f\"Opening {URL}\")\n",
    "driver.get(URL)\n",
    "time.sleep(5)  # Allow time for page to load\n",
    "\n",
    "# Scroll down to load more posts\n",
    "SCROLL_PAUSE_TIME = 3\n",
    "for _ in range(5):  # Adjust number of scrolls\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "# Find all post links\n",
    "post_links = driver.find_elements(By.XPATH, \"//a[contains(@href, '/p/')]\")\n",
    "post_urls = [link.get_attribute(\"href\") for link in post_links]\n",
    "\n",
    "print(f\"Found {len(post_urls)} posts.\")\n",
    "\n",
    "# Extract captions from the first few posts\n",
    "captions = []\n",
    "\n",
    "for link in post_urls[:5]:  # Scrape first 5 posts\n",
    "    print(f\"Scraping: {link}\")\n",
    "    driver.get(link)\n",
    "    time.sleep(5)  # Allow time for page to load\n",
    "\n",
    "    try:\n",
    "        caption_element = driver.find_element(By.XPATH, \"//div[@class='x1lliihq']\")  # Adjust class if needed\n",
    "        caption = caption_element.text\n",
    "        captions.append(caption)\n",
    "        print(f\"Caption: {caption}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not extract caption from {link}\")\n",
    "\n",
    "# Close browser\n",
    "driver.quit()\n",
    "\n",
    "# Print all found captions\n",
    "if captions:\n",
    "    print(\"\\n=== Captions Found ===\")\n",
    "    for idx, caption in enumerate(captions, start=1):\n",
    "        print(f\"{idx}. {caption}\")\n",
    "else:\n",
    "    print(\"No captions found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bridge)",
   "language": "python",
   "name": "biomedparse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
